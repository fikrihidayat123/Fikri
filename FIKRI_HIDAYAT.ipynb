{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsvhWrRWMV0BEWwCBOFZm1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fikrihidayat123/Fikri/blob/main/FIKRI_HIDAYAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "metadata": {
        "id": "gaBmElGQRZJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        ""
      ],
      "metadata": {
        "id": "93jc0_S9zLte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        ""
      ],
      "metadata": {
        "id": "mbQxjNx41B2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json #fungsi untuk memberikan izin akses file"
      ],
      "metadata": {
        "id": "OBMmEgTF1M6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d akshaydattatraykhare/diabetes-dataset"
      ],
      "metadata": {
        "id": "D9jOucGf-qpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Downloading diabetes-dataset.zip to /content\n",
        "\n",
        "  0% 0.00/8.91k [00:00<?, ?B/s]\n",
        "\n",
        "100% 8.91k/8.91k [00:00<00:00, 17.7MB/s]"
      ],
      "metadata": {
        "id": "iGTIyzdj-tTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('diabetes-dataset.zip',  'r') as zip_ref:\n",
        "      zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "d9D_2u9k_Cbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "6oYkNHKC_XEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetes.csv')\n",
        "display(df.head(2)) # display fisrt record of data\n",
        "display(df.tail(2)) # display last 4 rocord of data\n",
        "display(df.sample(4)) # display ramdomly any number of record of data"
      ],
      "metadata": {
        "id": "i1JhEQVQ_ghj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of rows and colums\n",
        "df.shape"
      ],
      "metadata": {
        "id": "wR7NGaXI1pkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "fUg5gMj-ApC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Info of the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "QSfFpJ8DA4sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tgugMzHzA6F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "j6vgyGIPBPQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape before drop duplicate\n",
        "df.shape"
      ],
      "metadata": {
        "id": "WFggFiXyBULa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop_duplicates()"
      ],
      "metadata": {
        "id": "UVtmdvc5BdyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape after drop the duplicate\n",
        "df.shape"
      ],
      "metadata": {
        "id": "HMVg79eRBjb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check of null vales,\n",
        "# check the missing value in any column\n",
        "# display number of null value in efery column indataset.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "prM4q-x1BqL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "gQZhBWDGBrr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('No of zero value in Glucose', df[df['Glucose']==0].shape)\n",
        "print ('No of zero value in BloodPressure', df[df['BloodPressure']==0].shape[0])\n",
        "print ('No of zero value in SkinThickness', df[df['SkinThickness']==0].shape[0])\n",
        "\n",
        "print ('No of zero value in Insulin', df[df['Insulin']==0].shape[0])\n",
        "print ('No of zero value in BMI', df[df['BMI']==0].shape[0])"
      ],
      "metadata": {
        "id": "FJ7HWCarBvGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Glucose']=df['Glucose'].replace(0,df['Glucose'].mean())\n",
        "print('no of zero value in Glucose',df[df['Glucose']==0].shape[0])\n",
        "\n",
        "df['BloodPressure']=df['BloodPressure'].replace(0,df['BloodPressure'].mean())\n",
        "df['SkinThickness']=df['SkinThickness'].replace(0,df['SkinThickness'].mean())\n",
        "df['Insulin']=df['Insulin'].replace(0,df['Insulin'].mean())\n",
        "df['BMI']=df['BMI'].replace(0,df['BMI'].mean())\n",
        ""
      ],
      "metadata": {
        "id": "Y4Tv-DebByny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "orlfWzoTB15-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utcome count plot\n",
        "f,ax=plt.subplots(1,2,figsize=(10,5))\n",
        "df['Outcome'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
        "ax[0].set_title('Outcome')\n",
        "ax[0].set_ylabel('')\n",
        "sns.countplot(x='Outcome',data=df,ax=ax[1])\n",
        "ax[1].set_title('Outcome')\n",
        "N,P = df['Outcome'].value_counts()\n",
        "print('Negative (0):',N)\n",
        "print('Positive (1):',P)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Se7qYXXMB4yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(bins=10, figsize=(10,10))\n",
        "plt.show\n",
        ""
      ],
      "metadata": {
        "id": "geZAOsNuB7vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df, figsize= (20,20));"
      ],
      "metadata": {
        "id": "lt0V-m1FCAKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "corrmat = df.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(10,10))\n",
        "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"viridis\")"
      ],
      "metadata": {
        "id": "IZ2pxJKHCE__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_name = 'Outcome'\n",
        "y = df[target_name]\n",
        "x = df.drop(target_name, axis=1)\n",
        "\n",
        "x.head()\n",
        "y.head()\n",
        ""
      ],
      "metadata": {
        "id": "ShunnhkDCI1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "SSX = scaler.transform(x)"
      ],
      "metadata": {
        "id": "MFape25pCMCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(SSX, y, test_size=0.2, random_state=7)\n",
        "\n",
        "\n",
        "x_train.shape, y_train.shape\n",
        "\n",
        "x_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "VSuLN8-UCOcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "sv=SVC()\n",
        "sv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "fAx640_UCTF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv_pred=sv.predict(x_test)\n",
        "sv_pred.shape\n",
        "(154,)"
      ],
      "metadata": {
        "id": "WQ3VbP2WCUO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train score &  test score SVM\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Train Accuracy of SVM\", sv.score(x_train, y_train)*100)\n",
        "print(\"Accuracy (test) score of SVM\", sv.score(x_test, y_test)*100)\n",
        "print(\"Accuracy (test) score of SVM\", accuracy_score(y_test, sv_pred)*100)"
      ],
      "metadata": {
        "id": "8RU05kv8CavT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Confusion matrix of Logistic Regression\n",
        "cm=confusion_matrix(y_test,sv_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "ygjLfY0-CdwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, sv_pred),annot=True,fmt='d')\n",
        ""
      ],
      "metadata": {
        "id": "b0wY1_u1Cgpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Classifiaction Report of SVM: \\n', classification_report(y_test,sv_pred,digits=4 ))\n",
        "TN = cm[0,0]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "TP = cm[1,1]"
      ],
      "metadata": {
        "id": "8gqy58mFCiL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the confusion matrix of SVM\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(y_test, sv_pred)\n",
        "cm\n",
        ""
      ],
      "metadata": {
        "id": "znCczm4BCldX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the confusion matrix of SVM\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "cm=confusion_matrix(y_test, sv_pred)\n",
        "\n",
        "\n",
        "print('TN - True Negative {}'. format(cm[0,0]))\n",
        "print('FP - True Positive {}'. format(cm[0,1]))\n",
        "print('FN - True Negative {}'. format(cm[1,0]))\n",
        "print('TP - True Positive {}'. format(cm[1,1]))\n",
        "print('Accuracy Rate of SVM:{}'.format(np.divide(np.sum([cm[0,0],cm[1,1]]),np.sum(cm))*100))\n",
        "print('Misclassification Rate of SVM :{}'.format(np.divide(np.sum([cm[0,1],cm[1,0]]),np.sum(cm))*100))"
      ],
      "metadata": {
        "id": "Nh6DPSWICoYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, sv_pred),cmap='Blues', annot=True, fmt=\"d\")"
      ],
      "metadata": {
        "id": "VJ4KcbDwCrkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report of SVM:\\n', classification_report(y_test,sv_pred,digits=4))"
      ],
      "metadata": {
        "id": "fmhly5IMCwCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRECISION (PPV-Positive Predicition Value)\n",
        "# Precision = TP/(TP+FP), Where TP = True Positive, FP = False Positive\n",
        "TP,FP\n"
      ],
      "metadata": {
        "id": "X8ZsAEQRC0ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score = TP/float(TP+FP)*100\n",
        "print('Precision Score : {0:0.4f}'.format(precision_score))\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"precision score is:\", precision_score(y_test,sv_pred)*100)\n",
        "print(\"Mirco Average precision Score is:\", precision_score(y_test, sv_pred, average='micro')*100)\n",
        "print(\"Marco Average precision Score is:\", precision_score(y_test, sv_pred, average='macro')*100)\n",
        "print(\"Weighted Average precision Score is:\", precision_score(y_test, sv_pred, average='weighted')*100)\n",
        "print(\"Precision Score on non weighted score is:\", precision_score(y_test, sv_pred, average=None)*100)\n",
        "\n",
        "recall_score = TP/float(TP + FN)*100\n",
        "print ('recall_score',recall_score)\n",
        "TP, FN"
      ],
      "metadata": {
        "id": "WLkU5_1eC2cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "print(\"Recall or Sensitivity_score :\", recall_score(y_test,sv_pred)*100)\n",
        "print(\"Micro Average Recall Score is :\", recall_score(y_test,sv_pred,average='micro')*100)\n",
        "print(\"Macro Average Recall Score is :\", recall_score(y_test,sv_pred,average='macro')*100)\n",
        "print(\"Weighted Average Recall Score is :\", recall_score(y_test,sv_pred,average='weighted')*100)\n",
        "print(\"Recall Score is :\", recall_score(y_test,sv_pred,average=None)*100)"
      ],
      "metadata": {
        "id": "AFlA8lEGC5VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Classification Report of Neural Network: \\n', classification_report(y_test,sv_pred,digits=4))"
      ],
      "metadata": {
        "id": "bJJxo86MDARm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FALSE POSITIVE RATE ( FPR )\n",
        "FPR = FP/float(FP+TN)*100\n",
        "print('False Positive Rate :{0:0.4f}' .format(FPR))"
      ],
      "metadata": {
        "id": "_0azWP4yDBN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SPECIFICITY\n",
        "specificity = TN /(TN+FP)*100\n",
        "print('specificity :{0:0.4f}' .format(specificity))"
      ],
      "metadata": {
        "id": "q7X0H3dtDETf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print ('f1_score of macro:',f1_score(y_test, sv_pred)*100)\n",
        "\n",
        "print(\"Micro Average f1 Score is :\", f1_score(y_test,sv_pred,average='micro')*100)\n",
        "print(\"Macro Average f1 Score is :\", f1_score(y_test,sv_pred,average='macro')*100)\n",
        "print(\"Weighted Average f1 Score is :\", f1_score(y_test,sv_pred,average='weighted')*100)\n",
        "print(\"f1 Score on weighted score is:\", f1_score(y_test,sv_pred,average=None)*100)"
      ],
      "metadata": {
        "id": "oHzv9MlLDHL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Area Under Curve\n",
        "auc = roc_auc_score(y_test, sv_pred)\n",
        "print(\"ROC AUC SCORE of SVM\",auc)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc = round(roc_auc_score(y_test,sv_pred)*100,2)\n",
        "print(\"ROC AUC SCORE of SVM is\",auc)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, sv_pred)\n",
        "plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "plt.plot([0,1],[0,1], color='darkblue', linestyle='--',label='ROC curve(area  + 0%.2f)'% auc)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) of SVM')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GTWtK-yoDMXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}